{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90579421",
   "metadata": {},
   "source": [
    "# Sentiment-Stock Analysis Pipeline\n",
    "\n",
    "## Overview\n",
    "1. ✅ Load tweets from Kaggle (80,793 tweets)\n",
    "2. ✅ Run sentiment analysis using Twitter-roBERTa NLP model\n",
    "3. Aggregate sentiment by date & ticker\n",
    "4. Fetch stock prices from Yahoo Finance\n",
    "5. Merge sentiment + prices\n",
    "6. Analyze correlation between sentiment and stock movements\n",
    "7. Train predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date  \\\n",
      "0  2022-09-29 23:41:16+00:00   \n",
      "1  2022-09-29 23:24:43+00:00   \n",
      "2  2022-09-29 23:18:08+00:00   \n",
      "3  2022-09-29 22:40:07+00:00   \n",
      "4  2022-09-29 22:27:05+00:00   \n",
      "\n",
      "                                               Tweet Stock Name Company Name  \n",
      "0  Mainstream media has done an amazing job at br...       TSLA  Tesla, Inc.  \n",
      "1  Tesla delivery estimates are at around 364k fr...       TSLA  Tesla, Inc.  \n",
      "2  3/ Even if I include 63.0M unvested RSUs as of...       TSLA  Tesla, Inc.  \n",
      "3  @RealDanODowd @WholeMarsBlog @Tesla Hahaha why...       TSLA  Tesla, Inc.  \n",
      "4  @RealDanODowd @Tesla Stop trying to kill kids,...       TSLA  Tesla, Inc.  \n",
      "Index(['Date', 'Tweet', 'Stock Name', 'Company Name'], dtype='object')\n",
      "(80793, 4)\n",
      "Date            object\n",
      "Tweet           object\n",
      "Stock Name      object\n",
      "Company Name    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "df_tweets = pd.read_csv('../data/stock_tweets.csv')\n",
    "print(f\"✅ Loaded {len(df_tweets):,} tweets\")\n",
    "print(f\"Date range: {df_tweets['Date'].min()} to {df_tweets['Date'].max()}\")\n",
    "print(f\"Tickers: {df_tweets['Stock Name'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8cb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sentiment analysis on all 80,793 tweets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tweets: 100%|██████████| 80793/80793 [23:58<00:00, 56.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Sentiment analysis complete!\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment_label\n",
      "Neutral     37921\n",
      "Positive    30418\n",
      "Negative    12454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment score stats:\n",
      "count    80793.000000\n",
      "mean         0.237951\n",
      "std          0.532447\n",
      "min         -0.953388\n",
      "25%         -0.078064\n",
      "50%          0.232134\n",
      "75%          0.725453\n",
      "max          0.990082\n",
      "Name: sentiment_score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load sentiment model\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Run sentiment analysis on all tweets\n",
    "sentiment_scores = []\n",
    "sentiment_labels = []\n",
    "\n",
    "print(\"Running sentiment analysis on all tweets...\")\n",
    "for tweet in tqdm(df_tweets['Tweet'], total=len(df_tweets), desc=\"Processing\"):\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
    "    \n",
    "    sentiment_score = probabilities[2] - probabilities[0]  # positive - negative\n",
    "    sentiment_label = ['Negative', 'Neutral', 'Positive'][probabilities.argmax()]\n",
    "    \n",
    "    sentiment_scores.append(sentiment_score)\n",
    "    sentiment_labels.append(sentiment_label)\n",
    "\n",
    "df_tweets['sentiment_score'] = sentiment_scores\n",
    "df_tweets['sentiment_label'] = sentiment_labels\n",
    "\n",
    "print(\"\\n✅ Sentiment analysis complete!\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df_tweets['sentiment_label'].value_counts())\n",
    "print(f\"\\nSentiment score stats:\")\n",
    "print(df_tweets['sentiment_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates first\n",
    "df_tweets['Date'] = pd.to_datetime(df_tweets['Date'])\n",
    "df_tweets['date'] = df_tweets['Date'].dt.date\n",
    "\n",
    "# Aggregate sentiment by date and ticker\n",
    "daily_sentiment = df_tweets.groupby(['date', 'Stock Name']).agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count'],\n",
    "    'sentiment_label': lambda x: (x == 'Positive').sum()\n",
    "}).reset_index()\n",
    "\n",
    "daily_sentiment.columns = ['date', 'ticker', 'sentiment_mean', 'sentiment_std', 'tweet_count', 'positive_count']\n",
    "daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "\n",
    "print(\"✅ Aggregated sentiment by date and ticker\")\n",
    "print(f\"\\nSample of daily sentiment:\")\n",
    "print(daily_sentiment.head(10))\n",
    "print(f\"\\nShape: {daily_sentiment.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock price data\n",
    "tickers = daily_sentiment['ticker'].unique().tolist()\n",
    "start_date = daily_sentiment['date'].min() - pd.Timedelta(days=5)\n",
    "end_date = daily_sentiment['date'].max() + pd.Timedelta(days=5)\n",
    "\n",
    "print(f\"Fetching prices for: {tickers}\")\n",
    "print(f\"Date range: {start_date.date()} to {end_date.date()}\\n\")\n",
    "\n",
    "stock_data = yf.download(tickers, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "# Process stock data\n",
    "price_list = []\n",
    "for ticker in tickers:\n",
    "    if len(tickers) > 1:\n",
    "        df_price = stock_data['Close'][ticker].reset_index()\n",
    "    else:\n",
    "        df_price = stock_data['Close'].reset_index()\n",
    "    \n",
    "    df_price.columns = ['date', 'close_price']\n",
    "    df_price['ticker'] = ticker\n",
    "    df_price['date'] = pd.to_datetime(df_price['date'])\n",
    "    df_price['price_change_pct'] = df_price['close_price'].pct_change() * 100\n",
    "    \n",
    "    price_list.append(df_price)\n",
    "\n",
    "stock_prices = pd.concat(price_list, ignore_index=True)\n",
    "\n",
    "print(f\"✅ Fetched stock prices for {len(stock_prices)} trading days\")\n",
    "print(f\"\\nSample stock data:\")\n",
    "print(stock_prices.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc788796",
   "metadata": {},
   "source": [
    "## Step 5: Merge Sentiment + Stock Prices\n",
    "\n",
    "Combine daily sentiment and stock prices for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f950260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sentiment and prices\n",
    "merged_df = daily_sentiment.merge(stock_prices, on=['date', 'ticker'], how='inner')\n",
    "merged_df = merged_df.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Merged sentiment + stock prices\")\n",
    "print(f\"\\nFinal dataset shape: {merged_df.shape}\")\n",
    "print(f\"Columns: {merged_df.columns.tolist()}\")\n",
    "print(f\"\\nTickers: {merged_df['ticker'].unique()}\")\n",
    "print(f\"Date range: {merged_df['date'].min().date()} to {merged_df['date'].max().date()}\")\n",
    "print(f\"\\nRecords per ticker:\")\n",
    "print(merged_df['ticker'].value_counts().sort_index())\n",
    "print(f\"\\nSample merged data:\")\n",
    "print(merged_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2daf5fd",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Sentiment-Price Correlation\n",
    "\n",
    "Does sentiment predict stock price movements? Calculate correlation for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e527194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between sentiment and price change\n",
    "print(\"Correlation between sentiment and price change (%):\\n\")\n",
    "\n",
    "for ticker in sorted(merged_df['ticker'].unique()):\n",
    "    ticker_data = merged_df[merged_df['ticker'] == ticker].copy()\n",
    "    ticker_data = ticker_data.dropna(subset=['sentiment_mean', 'price_change_pct'])\n",
    "    \n",
    "    if len(ticker_data) > 1:\n",
    "        corr = ticker_data['sentiment_mean'].corr(ticker_data['price_change_pct'])\n",
    "        print(f\"{ticker:5s}: {corr:7.3f}  (n={len(ticker_data):3d} days)\")\n",
    "\n",
    "# Visualize sentiment vs price for all tickers\n",
    "n_tickers = len(merged_df['ticker'].unique())\n",
    "fig, axes = plt.subplots((n_tickers + 1) // 2, 2, figsize=(14, 4 * ((n_tickers + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, ticker in enumerate(sorted(merged_df['ticker'].unique())):\n",
    "    ax = axes[idx]\n",
    "    ticker_data = merged_df[merged_df['ticker'] == ticker].dropna(subset=['sentiment_mean', 'price_change_pct'])\n",
    "    \n",
    "    ax.scatter(ticker_data['sentiment_mean'], ticker_data['price_change_pct'], alpha=0.6, s=30)\n",
    "    ax.set_xlabel('Daily Avg Sentiment Score', fontsize=10)\n",
    "    ax.set_ylabel('Daily Price Change %', fontsize=10)\n",
    "    ax.set_title(f'{ticker}: Sentiment vs Price Change', fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add correlation text\n",
    "    corr = ticker_data['sentiment_mean'].corr(ticker_data['price_change_pct'])\n",
    "    ax.text(0.05, 0.95, f'r={corr:.3f}', transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "            verticalalignment='top', fontsize=9)\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(len(merged_df['ticker'].unique()), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ DATA EXPLORATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nYour dataset is ready for modeling:\")\n",
    "print(f\"  • {len(merged_df):,} daily records\")\n",
    "print(f\"  • {len(merged_df['ticker'].unique())} stock tickers\")\n",
    "print(f\"  • Sentiment scores from NLP analysis\")\n",
    "print(f\"  • Stock prices and daily returns\")\n",
    "print(f\"  • Correlation analysis complete\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Add lag features (sentiment from previous days)\")\n",
    "print(f\"  2. Add technical indicators (volatility, moving averages)\")\n",
    "print(f\"  3. Train machine learning models (Linear, XGBoost, etc.)\")\n",
    "print(f\"  4. Evaluate with proper time-series validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
